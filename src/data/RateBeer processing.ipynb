{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beeradvocate pre-processing\n",
    "Given that the ratings.txt and reviews.txt are hard to pars and to handle we will convert them in a more easy to use format (parquet). We will also check how much information overlap between the two files to understand if we can drop one of them. <br>\n",
    "Finally we will do some processing on the reviews to make them compatible with our pipeline.<br><br><br>\n",
    "How to run this notebook:\n",
    "- Unpack all the files in the corresponding folder in the data folder\n",
    "- Run the notebook\n",
    "\n",
    "A converted reviews.pq and a converted ratings.pq will be saved in the data folder\n",
    "##### Definition of some global variables and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars as pl\n",
    "import tqdm\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../../data/RateBeer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identification of unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121075258it [00:42, 2836687.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in ratings.txt:\n",
      "{'brewery_name', 'brewery_id', 'beer_id', 'text', 'overall', 'beer_name', 'date', 'abv', 'palate', 'appearance', 'rating', 'user_name', 'taste', 'aroma', 'user_id', 'style'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121075258it [00:45, 2690329.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in reviews.txt:\n",
      "{'brewery_name', 'brewery_id', 'beer_id', 'text', 'overall', 'beer_name', 'date', 'abv', 'palate', 'appearance', 'rating', 'user_name', 'taste', 'aroma', 'user_id', 'style'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for file_name in [\"ratings\", \"reviews\"]:\n",
    "    unique_labels = set()\n",
    "    with open(f\"{DATA_FOLDER}/{file_name}.txt\") as file:\n",
    "        for line in tqdm.tqdm(file):\n",
    "            if line == \"\\n\":\n",
    "                continue\n",
    "            label, _ = line.split(\":\", 1)\n",
    "            unique_labels.add(label.strip())\n",
    "\n",
    "    print(f\"Unique labels in {file_name}.txt:\")\n",
    "    print(unique_labels)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conversion from txt to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7122074it [01:28, 80515.47it/s]\n",
      "7122074it [01:27, 80988.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define the mapping betwen column names and polars types\n",
    "mapping_pl = {\n",
    "    'rating': pl.Float64,\n",
    "    'palate': pl.Float64,\n",
    "    'abv': pl.Float64,\n",
    "    'beer_id': pl.Int64,\n",
    "    'beer_name': pl.Utf8,\n",
    "    'user_id': pl.Int64,\n",
    "    'taste': pl.Float64,\n",
    "    'date': pl.Datetime,\n",
    "    'style': pl.Utf8,\n",
    "    'appearance': pl.Float64,\n",
    "    'overall': pl.Float64,\n",
    "    'brewery_name': pl.Utf8,\n",
    "    'text': pl.Utf8,\n",
    "    'aroma': pl.Float64,\n",
    "    'user_name': pl.Utf8,\n",
    "    'brewery_id': pl.Int64\n",
    "}\n",
    "\n",
    "for file_name in [\"ratings\", \"reviews\"]:\n",
    "\n",
    "    # Create an empty list to collect rows\n",
    "    rows = []\n",
    "\n",
    "    # Open the file to read the reviews\n",
    "    with open(f\"{DATA_FOLDER}/{file_name}.txt\") as f:\n",
    "        for line in tqdm.tqdm(f):\n",
    "            # Remove leading/trailing whitespaces\n",
    "            line = line.strip()\n",
    "                \n",
    "            # Create a dictionary to store the content of the row\n",
    "            content = {label: None for label in mapping_pl.keys()}\n",
    "\n",
    "            # Process the line until we get a complete record\n",
    "            while line:\n",
    "                # Split the line into label and value\n",
    "                label, value = line.split(\":\", 1)\n",
    "                label = label.strip()\n",
    "                value = value.strip()\n",
    "\n",
    "                # Skip 'nan' values (these values are used to indicate missing data)\n",
    "                if value != 'nan':\n",
    "                    # Cast the value to the correct type based on the mapping\n",
    "                    if mapping_pl[label] == pl.Int64:\n",
    "                        value = int(value)\n",
    "                    elif mapping_pl[label] == pl.Float64:\n",
    "                        value = float(value)\n",
    "                    elif mapping_pl[label] == pl.Utf8:\n",
    "                        value = str(value)\n",
    "                    elif mapping_pl[label] == pl.Datetime:\n",
    "                        value = datetime.fromtimestamp(int(value))\n",
    "                    elif mapping_pl[label] == pl.Boolean:\n",
    "                        value = value == \"True\"\n",
    "\n",
    "                    # Store the value in the content dictionary\n",
    "                    content[label] = value\n",
    "\n",
    "                # Read the next line (for multiline records, like reviews)\n",
    "                line = f.readline().strip()\n",
    "\n",
    "            # Add the processed row to the list\n",
    "            rows.append(content)\n",
    "\n",
    "    # After processing all lines, create a DataFrame from the accumulated rows\n",
    "    df = pl.DataFrame(rows)\n",
    "\n",
    "    # Save it as parquet\n",
    "    df.write_parquet(f'{DATA_FOLDER}/{file_name}.pq')\n",
    "\n",
    "    # Free the memory\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overlap between ratings and reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pl.read_parquet(f'{DATA_FOLDER}/reviews.pq')\n",
    "ratings = pl.read_parquet(f'{DATA_FOLDER}/ratings.pq')\n",
    "\n",
    "assert pl.DataFrame.equals(reviews, ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that the reviews file and the ratings file contains the same information. We can drop the reviews file and keep only the ratings file (to be consistent with what has been done in with BeerAdvocate dataset)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
